{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecureK-means.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakib-Ul-Haque/SecureK-Means/blob/main/SecureK_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnGRQkj3jRRG"
      },
      "source": [
        "## **General K-means with Eucladian Distance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrA9hVnZCS_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d17884-86db-4ff9-92c9-6207796a9378"
      },
      "source": [
        "# Library Declaration  \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "# Data Input\n",
        "df = pd.read_table('breast-cancer-wisconsin.data', sep=',', names=[\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\",\"Mitoses\",\"Class\"]) \n",
        "print(df.head)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of      Sample code number  Clump Thickness  ...  Mitoses  Class\n",
            "0               1000025                5  ...        1      2\n",
            "1               1002945                5  ...        1      2\n",
            "2               1015425                3  ...        1      2\n",
            "3               1016277                6  ...        1      2\n",
            "4               1017023                4  ...        1      2\n",
            "..                  ...              ...  ...      ...    ...\n",
            "694              776715                3  ...        1      2\n",
            "695              841769                2  ...        1      2\n",
            "696              888820                5  ...        2      4\n",
            "697              897471                4  ...        1      4\n",
            "698              897471                4  ...        1      4\n",
            "\n",
            "[699 rows x 11 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cXZg1WRSH9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889f19bf-7df5-43f1-fa24-4fd5fb34ed96"
      },
      "source": [
        "# Data Cleaning\n",
        "df[\"Bare Nuclei\"][df[\"Bare Nuclei\"]=='?']='0'\n",
        "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(str).astype(int)\n",
        "df.info()\n",
        "# pd.to_numeric(df[\"Bare Nuclei\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699 entries, 0 to 698\n",
            "Data columns (total 11 columns):\n",
            " #   Column                       Non-Null Count  Dtype\n",
            "---  ------                       --------------  -----\n",
            " 0   Sample code number           699 non-null    int64\n",
            " 1   Clump Thickness              699 non-null    int64\n",
            " 2   Uniformity of Cell Size      699 non-null    int64\n",
            " 3   Uniformity of Cell Shape     699 non-null    int64\n",
            " 4   Marginal Adhesion            699 non-null    int64\n",
            " 5   Single Epithelial Cell Size  699 non-null    int64\n",
            " 6   Bare Nuclei                  699 non-null    int64\n",
            " 7   Bland Chromatin              699 non-null    int64\n",
            " 8   Normal Nucleoli              699 non-null    int64\n",
            " 9   Mitoses                      699 non-null    int64\n",
            " 10  Class                        699 non-null    int64\n",
            "dtypes: int64(11)\n",
            "memory usage: 60.2 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzzVWWduSdfo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2180ed-6efd-4d84-f78a-ecf7d29580e0"
      },
      "source": [
        "# Data Cleaning\n",
        "df=df.drop([\"Sample code number\"], axis = 1)\n",
        "print(df.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(699, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UF0q7KpSgSO"
      },
      "source": [
        "# Data Cleaning\n",
        "def Class_value(Class): \n",
        "     if Class == 2: \n",
        "         return 1\n",
        "     else: \n",
        "         return 0\n",
        "  \n",
        "df['Class'] = df['Class'].apply(Class_value) \n",
        "#df['Class'].head(10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbB2-NwGSjlv"
      },
      "source": [
        "# sf=df\n",
        "# ll = sf[\"Class\"].astype(float).values.tolist()\n",
        "# ll"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGwmMNU7nBl8",
        "outputId": "c2529093-91e4-4ddb-a4b8-cffb8f02c6cf"
      },
      "source": [
        "sf=df\n",
        "y = sf[\"Class\"].astype(float).values.tolist()\n",
        "y"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-vS78pDHio3"
      },
      "source": [
        "df=df.drop([\"Class\"], axis = 1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEdGmqx_nClL",
        "outputId": "a7bb2d7c-889e-4711-dce4-49eb9b244178"
      },
      "source": [
        "dataset = df.astype(float).values.tolist()\n",
        "\n",
        "X = df.values #returns a numpy array\n",
        "X"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  1,  1, ...,  3,  1,  1],\n",
              "       [ 5,  4,  4, ...,  3,  2,  1],\n",
              "       [ 3,  1,  1, ...,  3,  1,  1],\n",
              "       ...,\n",
              "       [ 5, 10, 10, ...,  8, 10,  2],\n",
              "       [ 4,  8,  6, ..., 10,  6,  1],\n",
              "       [ 4,  8,  8, ..., 10,  4,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudOTGv6Vnyv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t77nuiAsVJHR"
      },
      "source": [
        "class KMeans:\n",
        "    \n",
        "    def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "        \n",
        "        self.k = k\n",
        "        self.n_iter = n_iter\n",
        "        self.plot_step = plot_step\n",
        "        self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "        self.centroids = []     # center of each cluster\n",
        "        \n",
        "    def distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1-x2)**2))\n",
        "    \n",
        "    def cluster_plot(self):\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        \n",
        "        for i, index in enumerate(self.clusters):\n",
        "            point = self.X[index].T\n",
        "            ax.scatter(*point)\n",
        "        \n",
        "        for centroid in self.centroids:\n",
        "            ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "        plt.show()\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \n",
        "        self.X = X\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "        \n",
        "        # initialize k random centroids\n",
        "        k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "        self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "        \n",
        "        # optimize clusters\n",
        "        for _ in range(self.n_iter):\n",
        "            \n",
        "            # update clusters\n",
        "            self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "            if self.plot_step:\n",
        "                self.cluster_plot()\n",
        "                \n",
        "            # update centroids\n",
        "            old_centroids = self.centroids\n",
        "            self.centroids = self._get_new_centroids(self.clusters)\n",
        "            \n",
        "            # check clusters converged\n",
        "            if self._is_converged(old_centroids, self.centroids):\n",
        "                break\n",
        "                \n",
        "        return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "            \n",
        "    def _create_clusters(self, centroids):\n",
        "        \n",
        "        clusters = [[] for _ in range(self.k)]\n",
        "        \n",
        "        for ids, sample in enumerate(self.X):\n",
        "            centroid_id = self._closest_centroid(sample, centroids)\n",
        "            clusters[centroid_id].append(ids)\n",
        "        return clusters\n",
        "            \n",
        "            \n",
        "    def _closest_centroid(self, sample, centroids):\n",
        "        \n",
        "        distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "        closest_id = np.argmin(distances)\n",
        "        return closest_id\n",
        "        \n",
        "    def _get_new_centroids(self, clusters):\n",
        "        \n",
        "        centroids = np.zeros((self.k, self.n_features))\n",
        "        for cluster_id, cluster in enumerate(clusters):\n",
        "            new_centroid = np.mean(X[cluster], axis=0)\n",
        "            centroids[cluster_id] = new_centroid\n",
        "        return centroids\n",
        "    \n",
        "    def _is_converged(self, old_centroids, new_centroids):\n",
        "        \n",
        "        distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "        return sum(distances) == 0\n",
        "    \n",
        "    def _get_cluster_label(self, clusters):\n",
        "        \n",
        "        labels = np.empty(self.n_samples)\n",
        "        for cluster_id, cluster in enumerate(clusters):\n",
        "            for sample_id in cluster:\n",
        "                labels[sample_id] = cluster_id\n",
        "        return labels"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rUwmG4VPiZ"
      },
      "source": [
        "kmean = KMeans(k=2, n_iter=150, plot_step=False)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDRuE5P3Vbex"
      },
      "source": [
        "# from sklearn.datasets import make_blobs\n",
        "# X, y = make_blobs(centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40)\n",
        "y_predict = kmean.predict(X)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN3Y6_FgZ-aI"
      },
      "source": [
        "# accuracy = np.sum(y == y_predict) / len(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCYVE2uxaKD-"
      },
      "source": [
        "# accuracy"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9YNlVUfYhhB"
      },
      "source": [
        "s=y_predict.tolist()\n",
        "# s"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDbY6W7NIwQj"
      },
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.preprocessing import StandardScaler, normalize\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.metrics import silhouette_score"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhs77W-VG7Dq"
      },
      "source": [
        "# sse = {}\n",
        "# for k in range(1, 10):\n",
        "#     kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X)\n",
        "#     sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
        "# plt.figure()\n",
        "# plt.plot(list(sse.keys()), list(sse.values()))\n",
        "# plt.xlabel(\"Number of cluster\")\n",
        "# plt.ylabel(\"SSE\")\n",
        "# plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahrVCTxcG8LG"
      },
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# # from sklearn.datasets import make_blobs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rzKzL0G8Hd"
      },
      "source": [
        "# class KMeans:\n",
        "    \n",
        "#     def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "        \n",
        "#         self.k = k\n",
        "#         self.n_iter = n_iter\n",
        "#         self.plot_step = plot_step\n",
        "#         self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "#         self.centroids = []     # center of each cluster\n",
        "        \n",
        "#     def distance(self, x1, x2):\n",
        "#         return np.sqrt(np.sum((x1-x2)**2))\n",
        "    \n",
        "#     def cluster_plot(self):\n",
        "        \n",
        "#         fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        \n",
        "#         for i, index in enumerate(self.clusters):\n",
        "#             point = self.X[index].T\n",
        "#             ax.scatter(*point)\n",
        "        \n",
        "#         for centroid in self.centroids:\n",
        "#             ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "#         plt.show()\n",
        "        \n",
        "#     def predict(self, X):\n",
        "        \n",
        "#         self.X = X\n",
        "#         self.n_samples, self.n_features = X.shape\n",
        "        \n",
        "#         # initialize k random centroids\n",
        "#         k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "#         self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "        \n",
        "#         # optimize clusters\n",
        "#         for _ in range(self.n_iter):\n",
        "            \n",
        "#             # update clusters\n",
        "#             self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "#             if self.plot_step:\n",
        "#                 self.cluster_plot()\n",
        "                \n",
        "#             # update centroids\n",
        "#             old_centroids = self.centroids\n",
        "#             self.centroids = self._get_new_centroids(self.clusters)\n",
        "            \n",
        "#             # check clusters converged\n",
        "#             if self._is_converged(old_centroids, self.centroids):\n",
        "#                 break\n",
        "                \n",
        "#         return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "            \n",
        "#     def _create_clusters(self, centroids):\n",
        "        \n",
        "#         clusters = [[] for _ in range(self.k)]\n",
        "        \n",
        "#         for ids, sample in enumerate(self.X):\n",
        "#             centroid_id = self._closest_centroid(sample, centroids)\n",
        "#             clusters[centroid_id].append(ids)\n",
        "#         return clusters\n",
        "            \n",
        "            \n",
        "#     def _closest_centroid(self, sample, centroids):\n",
        "        \n",
        "#         distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "#         closest_id = np.argmin(distances)\n",
        "#         return closest_id\n",
        "        \n",
        "#     def _get_new_centroids(self, clusters):\n",
        "        \n",
        "#         centroids = np.zeros((self.k, self.n_features))\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             new_centroid = np.mean(X[cluster], axis=0)\n",
        "#             centroids[cluster_id] = new_centroid\n",
        "#         return centroids\n",
        "    \n",
        "#     def _is_converged(self, old_centroids, new_centroids):\n",
        "        \n",
        "#         distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "#         return sum(distances) == 0\n",
        "    \n",
        "#     def _get_cluster_label(self, clusters):\n",
        "        \n",
        "#         labels = np.empty(self.n_samples)\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             for sample_id in cluster:\n",
        "#                 labels[sample_id] = cluster_id\n",
        "#         return labels"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in44t2fgG8EN"
      },
      "source": [
        "# kmean = KMeans(k=2, n_iter=150, plot_step=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVJyvJrTG78O"
      },
      "source": [
        "# y_predict = kmean.predict(X)\n",
        "# print(kmean)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzHFwHoG7s6"
      },
      "source": [
        "# l=kmean.labels\n",
        "# l"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQuu_VTA1XXL",
        "outputId": "c61e3192-ebb6-4f39-b6c2-22153f438fa8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print(confusion_matrix(s,y))\n",
        "print(classification_report(s,y))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[223  11]\n",
            " [ 18 447]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.95      0.94       234\n",
            "         1.0       0.98      0.96      0.97       465\n",
            "\n",
            "    accuracy                           0.96       699\n",
            "   macro avg       0.95      0.96      0.95       699\n",
            "weighted avg       0.96      0.96      0.96       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARZ4w7unJAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0470a70-72e9-40e6-e4bd-954135524a21"
      },
      "source": [
        "# knn = KNeighborsClassifier(n_neighbors = 15, metric='manhattan')# metric='euclidean') #metric='minkowski') \n",
        "# knn.fit(X_train, y_train) \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# kmeans.score(X_test, y_test) \n",
        "# y_pred=knn.predict(X_test)\n",
        "acc=(metrics.accuracy_score(s,y)*100)\n",
        "print(acc)    \n",
        "# knn.score(X_test, y_test) \n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "pre=(precision_score(s,y)*100) #average='binary')*100)\n",
        "print(pre)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "rec=(recall_score(s,y)*100)# average='binary')*100)\n",
        "print(rec)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1=(f1_score(s,y))# average='binary')*100)\n",
        "print(f1) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.85121602288984\n",
            "97.59825327510917\n",
            "96.12903225806451\n",
            "0.9685807150595883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-KjIxgFj0dh"
      },
      "source": [
        "## **General K-means with Manhattan Distance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrgSNytnj9NI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}