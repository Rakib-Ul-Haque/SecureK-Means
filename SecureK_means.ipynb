{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecureK-means.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rakib-Ul-Haque/SecureK-Means/blob/main/SecureK_means.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnGRQkj3jRRG"
      },
      "source": [
        "## **General K-means with Manhattan Distance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrA9hVnZCS_M"
      },
      "source": [
        "# # Library Declaration  \n",
        "# import numpy as np\n",
        "# import pandas as pd \n",
        "# # Data Input\n",
        "# df = pd.read_table('breast-cancer-wisconsin.data', sep=',', names=[\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\",\"Mitoses\",\"Class\"]) \n",
        "# # print(df.head)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cXZg1WRSH9-"
      },
      "source": [
        "# # Data Cleaning\n",
        "# df[\"Bare Nuclei\"][df[\"Bare Nuclei\"]=='?']='0'\n",
        "# df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(str).astype(int)\n",
        "# # df.info()\n",
        "# # pd.to_numeric(df[\"Bare Nuclei\"])"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzzVWWduSdfo"
      },
      "source": [
        "# # Data Cleaning\n",
        "# df=df.drop([\"Sample code number\"], axis = 1)\n",
        "# # print(df.shape)"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UF0q7KpSgSO"
      },
      "source": [
        "# # Data Cleaning\n",
        "# def Class_value(Class): \n",
        "#      if Class == 2: \n",
        "#          return 1\n",
        "#      else: \n",
        "#          return 0\n",
        "  \n",
        "# df['Class'] = df['Class'].apply(Class_value) \n",
        "# #df['Class'].head(10)"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbB2-NwGSjlv"
      },
      "source": [
        "# sf=df\n",
        "# ll = sf[\"Class\"].astype(float).values.tolist()\n",
        "# ll"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGwmMNU7nBl8"
      },
      "source": [
        "# sf=df\n",
        "# y = sf[\"Class\"].astype(float).values.tolist()\n",
        "# # y"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-vS78pDHio3"
      },
      "source": [
        "# df=df.drop([\"Class\"], axis = 1)"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEdGmqx_nClL"
      },
      "source": [
        "# dataset = df.astype(float).values.tolist()\n",
        "\n",
        "# X = df.values #returns a numpy array\n",
        "# X"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LudOTGv6Vnyv"
      },
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.preprocessing import StandardScaler, normalize\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.metrics import silhouette_score"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW2-uO6KoCta"
      },
      "source": [
        "# def distance(self, x1, x2):\n",
        "    #   distance = 0.0\n",
        "    #   for i in range(len(x1)-1):\n",
        "    #     if (x1[i]>=x2[i]):\n",
        "    #       distance +=(x1[i] - x2[i])\n",
        "    #     else:\n",
        "    #       distance += (x2[i] - x1[i])\n",
        "      # #print(distance)\n",
        "    #   return distance#np.sqrt(np.sum((x1-x2)**2))\n",
        "      \n",
        "    # calculate the Manhatan distance between two vectors\n",
        "    # def manhatan_distance(row1, row2):\n",
        "    #   distance = 0.0\n",
        "    #   for i in range(len(row1)-1):\n",
        "    #     if (row1[i]>=row2[i]):\n",
        "    #       distance +=(row1[i] - row2[i])\n",
        "    #     else:\n",
        "    #       distance += (row2[i] - row1[i])\n",
        "    #   return distance"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTla6-dKp7i2"
      },
      "source": [
        "# class KMeans:\n",
        "    \n",
        "#     def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "        \n",
        "#         self.k = k\n",
        "#         self.n_iter = n_iter\n",
        "#         self.plot_step = plot_step\n",
        "#         self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "#         self.centroids = []     # center of each cluster\n",
        "        \n",
        "#     def distance(self, x1, x2):\n",
        "#       disce = 0.0\n",
        "#       for i in range(len(x1)-1):\n",
        "#         if (x1[i]>=x2[i]):\n",
        "#           disce +=(x1[i] - x2[i])\n",
        "#         else:\n",
        "#           disce += (x2[i] - x1[i])\n",
        "#       return disce\n",
        "#       #print(distance)\n",
        "\n",
        "\n",
        "#     # def distance(self, x1, x2):\n",
        "#     #     return np.sqrt(np.sum((x1-x2)**2))\n",
        "    \n",
        "#     def cluster_plot(self):\n",
        "        \n",
        "#         fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        \n",
        "#         for i, index in enumerate(self.clusters):\n",
        "#             point = self.X[index].T\n",
        "#             ax.scatter(*point)\n",
        "        \n",
        "#         for centroid in self.centroids:\n",
        "#             ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "#         plt.show()\n",
        "        \n",
        "#     def predict(self, X):\n",
        "        \n",
        "#         self.X = X\n",
        "#         self.n_samples, self.n_features = X.shape\n",
        "        \n",
        "#         # initialize k random centroids\n",
        "#         k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "#         self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "        \n",
        "#         # optimize clusters\n",
        "#         for _ in range(self.n_iter):\n",
        "            \n",
        "#             # update clusters\n",
        "#             self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "#             if self.plot_step:\n",
        "#                 self.cluster_plot()\n",
        "                \n",
        "#             # update centroids\n",
        "#             old_centroids = self.centroids\n",
        "#             self.centroids = self._get_new_centroids(self.clusters)\n",
        "            \n",
        "#             # check clusters converged\n",
        "#             if self._is_converged(old_centroids, self.centroids):\n",
        "#                 break\n",
        "                \n",
        "#         return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "            \n",
        "#     def _create_clusters(self, centroids):\n",
        "        \n",
        "#         clusters = [[] for _ in range(self.k)]\n",
        "        \n",
        "#         for ids, sample in enumerate(self.X):\n",
        "#             centroid_id = self._closest_centroid(sample, centroids)\n",
        "#             clusters[centroid_id].append(ids)\n",
        "#         return clusters\n",
        "            \n",
        "            \n",
        "#     def _closest_centroid(self, sample, centroids):\n",
        "        \n",
        "#         distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "#         closest_id = np.argmin(distances)\n",
        "#         return closest_id\n",
        "        \n",
        "#     def _get_new_centroids(self, clusters):\n",
        "        \n",
        "#         centroids = np.zeros((self.k, self.n_features))\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             new_centroid = np.mean(X[cluster], axis=0)\n",
        "#             centroids[cluster_id] = new_centroid\n",
        "#         return centroids\n",
        "    \n",
        "#     def _is_converged(self, old_centroids, new_centroids):\n",
        "        \n",
        "#         distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "#         return sum(distances) == 0\n",
        "    \n",
        "#     def _get_cluster_label(self, clusters):\n",
        "        \n",
        "#         labels = np.empty(self.n_samples)\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             for sample_id in cluster:\n",
        "#                 labels[sample_id] = cluster_id\n",
        "#         return labels"
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t77nuiAsVJHR"
      },
      "source": [
        "# class KMeans:\n",
        "#   def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "#     self.k = k\n",
        "#     self.n_iter = n_iter\n",
        "#     self.plot_step = plot_step\n",
        "#     self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "#     self.centroids = []     # center of each cluster\n",
        "  \n",
        "#   def distance(self, x1, x2):\n",
        "#     return np.sqrt(np.sum((x1-x2)**2))\n",
        "  \n",
        "#   def cluster_plot(self):\n",
        "#     fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "#     for i, index in enumerate(self.clusters):\n",
        "#       point = self.X[index].T\n",
        "#       ax.scatter(*point)\n",
        "      \n",
        "#     for centroid in self.centroids:\n",
        "#       ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "#       plt.show()\n",
        "  \n",
        "#   def predict(self, X):\n",
        "#     self.X = X\n",
        "#     self.n_samples, self.n_features = X.shape\n",
        "#     # initialize k random centroids\n",
        "#     k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "#     self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "#     # optimize clusters\n",
        "#     for _ in range(self.n_iter):\n",
        "#       # update clusters\n",
        "#       self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "#       if self.plot_step:\n",
        "#         self.cluster_plot()\n",
        "#         # update centroids\n",
        "#         old_centroids = self.centroids\n",
        "#         self.centroids = self._get_new_centroids(self.clusters)\n",
        "#         # check clusters converged\n",
        "#         if self._is_converged(old_centroids, self.centroids):\n",
        "#           break\n",
        "#     return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "#   def _create_clusters(self, centroids):\n",
        "#     clusters = [[] for _ in range(self.k)]\n",
        "#     for ids, sample in enumerate(self.X):\n",
        "#       centroid_id = self._closest_centroid(sample, centroids)\n",
        "#       clusters[centroid_id].append(ids)\n",
        "#     return clusters\n",
        "  \n",
        "#   def _closest_centroid(self, sample, centroids):\n",
        "#     distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "#     closest_id = np.argmin(distances)\n",
        "#     return closest_id\n",
        "    \n",
        "#   def _get_new_centroids(self, clusters):\n",
        "#     centroids = np.zeros((self.k, self.n_features))\n",
        "#     for cluster_id, cluster in enumerate(clusters):\n",
        "#       new_centroid = np.mean(X[cluster], axis=0)\n",
        "#       centroids[cluster_id] = new_centroid\n",
        "#     return centroids\n",
        "    \n",
        "#   def _is_converged(self, old_centroids, new_centroids):\n",
        "#     distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "#     return sum(distances) == 0\n",
        "    \n",
        "#   def _get_cluster_label(self, clusters):\n",
        "#     labels = np.empty(self.n_samples)\n",
        "#     for cluster_id, cluster in enumerate(clusters):\n",
        "#       for sample_id in cluster:\n",
        "#         labels[sample_id] = cluster_id\n",
        "#     return labels"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rUwmG4VPiZ"
      },
      "source": [
        "# kmean = KMeans(k=2, n_iter=150, plot_step=False)"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDRuE5P3Vbex"
      },
      "source": [
        "# # from sklearn.datasets import make_blobs\n",
        "# # X, y = make_blobs(centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40)\n",
        "# y_predict = kmean.predict(X)"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN3Y6_FgZ-aI"
      },
      "source": [
        "\n",
        "# accuracy = np.sum(y == y_predict) / len(y)"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCYVE2uxaKD-"
      },
      "source": [
        "\n",
        "# accuracy"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9YNlVUfYhhB"
      },
      "source": [
        "\n",
        "# s=y_predict.tolist()\n",
        "# # s"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDbY6W7NIwQj"
      },
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.preprocessing import StandardScaler, normalize\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.metrics import silhouette_score\n"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhs77W-VG7Dq"
      },
      "source": [
        "# sse = {}\n",
        "# for k in range(1, 10):\n",
        "#     kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X)\n",
        "#     sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
        "# plt.figure()\n",
        "# plt.plot(list(sse.keys()), list(sse.values()))\n",
        "# plt.xlabel(\"Number of cluster\")\n",
        "# plt.ylabel(\"SSE\")\n",
        "# plt.show()"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahrVCTxcG8LG"
      },
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# # from sklearn.datasets import make_blobs"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rzKzL0G8Hd"
      },
      "source": [
        "# class KMeans:\n",
        "    \n",
        "#     def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "        \n",
        "#         self.k = k\n",
        "#         self.n_iter = n_iter\n",
        "#         self.plot_step = plot_step\n",
        "#         self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "#         self.centroids = []     # center of each cluster\n",
        "        \n",
        "#     def distance(self, x1, x2):\n",
        "#         return np.sqrt(np.sum((x1-x2)**2))\n",
        "    \n",
        "#     def cluster_plot(self):\n",
        "        \n",
        "#         fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        \n",
        "#         for i, index in enumerate(self.clusters):\n",
        "#             point = self.X[index].T\n",
        "#             ax.scatter(*point)\n",
        "        \n",
        "#         for centroid in self.centroids:\n",
        "#             ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "#         plt.show()\n",
        "        \n",
        "#     def predict(self, X):\n",
        "        \n",
        "#         self.X = X\n",
        "#         self.n_samples, self.n_features = X.shape\n",
        "        \n",
        "#         # initialize k random centroids\n",
        "#         k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "#         self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "        \n",
        "#         # optimize clusters\n",
        "#         for _ in range(self.n_iter):\n",
        "            \n",
        "#             # update clusters\n",
        "#             self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "#             if self.plot_step:\n",
        "#                 self.cluster_plot()\n",
        "                \n",
        "#             # update centroids\n",
        "#             old_centroids = self.centroids\n",
        "#             self.centroids = self._get_new_centroids(self.clusters)\n",
        "            \n",
        "#             # check clusters converged\n",
        "#             if self._is_converged(old_centroids, self.centroids):\n",
        "#                 break\n",
        "                \n",
        "#         return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "            \n",
        "#     def _create_clusters(self, centroids):\n",
        "        \n",
        "#         clusters = [[] for _ in range(self.k)]\n",
        "        \n",
        "#         for ids, sample in enumerate(self.X):\n",
        "#             centroid_id = self._closest_centroid(sample, centroids)\n",
        "#             clusters[centroid_id].append(ids)\n",
        "#         return clusters\n",
        "            \n",
        "            \n",
        "#     def _closest_centroid(self, sample, centroids):\n",
        "        \n",
        "#         distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "#         closest_id = np.argmin(distances)\n",
        "#         return closest_id\n",
        "        \n",
        "#     def _get_new_centroids(self, clusters):\n",
        "        \n",
        "#         centroids = np.zeros((self.k, self.n_features))\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             new_centroid = np.mean(X[cluster], axis=0)\n",
        "#             centroids[cluster_id] = new_centroid\n",
        "#         return centroids\n",
        "    \n",
        "#     def _is_converged(self, old_centroids, new_centroids):\n",
        "        \n",
        "#         distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "#         return sum(distances) == 0\n",
        "    \n",
        "#     def _get_cluster_label(self, clusters):\n",
        "        \n",
        "#         labels = np.empty(self.n_samples)\n",
        "#         for cluster_id, cluster in enumerate(clusters):\n",
        "#             for sample_id in cluster:\n",
        "#                 labels[sample_id] = cluster_id\n",
        "#         return labels"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in44t2fgG8EN"
      },
      "source": [
        "# kmean = KMeans(k=2, n_iter=150, plot_step=False)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVJyvJrTG78O"
      },
      "source": [
        "# y_predict = kmean.predict(X)\n",
        "# print(kmean)"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MzHFwHoG7s6"
      },
      "source": [
        "# l=kmean.labels\n",
        "# l"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQuu_VTA1XXL"
      },
      "source": [
        "# from sklearn.metrics import confusion_matrix,classification_report\n",
        "# print(confusion_matrix(s,y))\n",
        "# print(classification_report(s,y))"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARZ4w7unJAb"
      },
      "source": [
        "# # knn = KNeighborsClassifier(n_neighbors = 15, metric='manhattan')# metric='euclidean') #metric='minkowski') \n",
        "# # knn.fit(X_train, y_train) \n",
        "# from sklearn import metrics \n",
        "# from sklearn.metrics import precision_recall_fscore_support\n",
        "# # kmeans.score(X_test, y_test) \n",
        "# # y_pred=knn.predict(X_test)\n",
        "# acc=(metrics.accuracy_score(s,y)*100)\n",
        "# print(acc)    \n",
        "# # knn.score(X_test, y_test) \n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# pre=(precision_score(s,y)*100) #average='binary')*100)\n",
        "# print(pre)\n",
        "\n",
        "# from sklearn.metrics import recall_score\n",
        "# rec=(recall_score(s,y)*100)# average='binary')*100)\n",
        "# print(rec)\n",
        "\n",
        "# from sklearn.metrics import f1_score\n",
        "# f1=(f1_score(s,y))# average='binary')*100)\n",
        "# print(f1) "
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-KjIxgFj0dh"
      },
      "source": [
        "## **Secure K-means with Manhattan Distance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrgSNytnj9NI",
        "outputId": "adf47572-7555-4509-df8c-205ed001c6ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Library Declaration  \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "# Data Input\n",
        "df = pd.read_table('breast-cancer-wisconsin.data', sep=',', names=[\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\",\"Mitoses\",\"Class\"]) \n",
        "# print(df.head)\n",
        "# Data Cleaning\n",
        "df[\"Bare Nuclei\"][df[\"Bare Nuclei\"]=='?']='0'\n",
        "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(str).astype(int)\n",
        "# df.info()\n",
        "# pd.to_numeric(df[\"Bare Nuclei\"])\n",
        "# Data Cleaning\n",
        "\n",
        "df=df.drop([\"Sample code number\"], axis = 1)\n",
        "# print(df.shape)\n",
        "# Data Cleaning\n",
        "\n",
        "def Class_value(Class): \n",
        "     if Class == 2: \n",
        "         return 1\n",
        "     else: \n",
        "         return 0\n",
        "  \n",
        "df['Class'] = df['Class'].apply(Class_value) \n",
        "#df['Class'].head(10)\n",
        "sf=df\n",
        "y = sf[\"Class\"].astype(float).values.tolist()\n",
        "# y\n",
        "\n",
        "df=df.drop([\"Class\"], axis = 1)\n",
        "\n",
        "dataset = df.astype(float).values.tolist()\n",
        "\n",
        "X = df.values #returns a numpy array\n",
        "X"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  1,  1, ...,  3,  1,  1],\n",
              "       [ 5,  4,  4, ...,  3,  2,  1],\n",
              "       [ 3,  1,  1, ...,  3,  1,  1],\n",
              "       ...,\n",
              "       [ 5, 10, 10, ...,  8, 10,  2],\n",
              "       [ 4,  8,  6, ..., 10,  6,  1],\n",
              "       [ 4,  8,  8, ..., 10,  4,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrc1DFKpsYPl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwVGLHxYsc0q"
      },
      "source": [
        "class KMeans:\n",
        "    \n",
        "    def __init__(self, k=5, n_iter=100, plot_step=False):\n",
        "        \n",
        "        self.k = k\n",
        "        self.n_iter = n_iter\n",
        "        self.plot_step = plot_step\n",
        "        self.clusters = [[] for _ in range(self.k)]    # list of each cluster\n",
        "        self.centroids = []     # center of each cluster\n",
        "        \n",
        "    def distance(self, x1, x2):\n",
        "      disce = 0.0\n",
        "      for i in range(len(x1)-1):\n",
        "        if (x1[i]>=x2[i]):\n",
        "          disce +=(x1[i] - x2[i])\n",
        "        else:\n",
        "          disce += (x2[i] - x1[i])\n",
        "      return disce\n",
        "      #print(distance)\n",
        "\n",
        "\n",
        "    # def distance(self, x1, x2):\n",
        "    #     return np.sqrt(np.sum((x1-x2)**2))\n",
        "    \n",
        "    def cluster_plot(self):\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        \n",
        "        for i, index in enumerate(self.clusters):\n",
        "            point = self.X[index].T\n",
        "            ax.scatter(*point)\n",
        "        \n",
        "        for centroid in self.centroids:\n",
        "            ax.scatter(*centroid, marker='x', color='black', linewidth=2)\n",
        "        plt.show()\n",
        "        \n",
        "    def predict(self, X):\n",
        "        \n",
        "        self.X = X\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "        \n",
        "        # initialize k random centroids\n",
        "        k_random_sample_ids = np.random.choice(self.n_samples, self.k, replace=False)\n",
        "        self.centroids = [self.X[ids] for ids in k_random_sample_ids]\n",
        "        \n",
        "        # optimize clusters\n",
        "        for _ in range(self.n_iter):\n",
        "            \n",
        "            # update clusters\n",
        "            self.clusters = self._create_clusters(self.centroids)     # get clusters from create clusters\n",
        "            if self.plot_step:\n",
        "                self.cluster_plot()\n",
        "                \n",
        "            # update centroids\n",
        "            old_centroids = self.centroids\n",
        "            self.centroids = self._get_new_centroids(self.clusters)\n",
        "            \n",
        "            # check clusters converged\n",
        "            if self._is_converged(old_centroids, self.centroids):\n",
        "                break\n",
        "                \n",
        "        return self._get_cluster_label(self.clusters)\n",
        "    \n",
        "            \n",
        "    def _create_clusters(self, centroids):\n",
        "        \n",
        "        clusters = [[] for _ in range(self.k)]\n",
        "        \n",
        "        for ids, sample in enumerate(self.X):\n",
        "            centroid_id = self._closest_centroid(sample, centroids)\n",
        "            clusters[centroid_id].append(ids)\n",
        "        return clusters\n",
        "            \n",
        "            \n",
        "    def _closest_centroid(self, sample, centroids):\n",
        "        \n",
        "        distances = [self.distance(sample, centroid) for centroid in centroids]\n",
        "        closest_id = np.argmin(distances)\n",
        "        return closest_id\n",
        "        \n",
        "    def _get_new_centroids(self, clusters):\n",
        "        # print(clusters)\n",
        "        centroids = np.zeros((self.k, self.n_features))\n",
        "        for cluster_id, cluster in enumerate(clusters):\n",
        "          # print(\"dfd:\",X[cluster])\n",
        "          new_centroid = np.mean(X[cluster], axis=0)\n",
        "          centroids[cluster_id] = new_centroid\n",
        "          # print(\"fff:\",centroids)\n",
        "        return centroids\n",
        "    \n",
        "    def _is_converged(self, old_centroids, new_centroids):\n",
        "        distances = [self.distance(old_centroids[i], new_centroids[i]) for i in range(self.k)]\n",
        "        return sum(distances) == 0\n",
        "    \n",
        "    def _get_cluster_label(self, clusters):\n",
        "        \n",
        "        labels = np.empty(self.n_samples)\n",
        "        for cluster_id, cluster in enumerate(clusters):\n",
        "            for sample_id in cluster:\n",
        "                labels[sample_id] = cluster_id\n",
        "        return labels"
      ],
      "execution_count": 486,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCiQ521GslPB",
        "outputId": "622e83eb-50bb-4911-8fca-2a44cf2881e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kmean = KMeans(k=2, n_iter=150, plot_step=False)\n",
        "y_predict = kmean.predict(X)"
      ],
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dfd: [[ 5  4  4 ...  3  2  1]\n",
            " [ 6  8  8 ...  3  7  1]\n",
            " [ 8 10 10 ...  9  7  1]\n",
            " ...\n",
            " [ 5 10 10 ...  8 10  2]\n",
            " [ 4  8  6 ... 10  6  1]\n",
            " [ 4  8  8 ... 10  4  1]]\n",
            "dfd: [[5 1 1 ... 3 1 1]\n",
            " [3 1 1 ... 3 1 1]\n",
            " [4 1 1 ... 3 1 1]\n",
            " ...\n",
            " [3 1 1 ... 2 1 2]\n",
            " [3 1 1 ... 1 1 1]\n",
            " [2 1 1 ... 1 1 1]]\n",
            "dfd: [[ 5  4  4 ...  3  2  1]\n",
            " [ 6  8  8 ...  3  7  1]\n",
            " [ 8 10 10 ...  9  7  1]\n",
            " ...\n",
            " [ 5 10 10 ...  8 10  2]\n",
            " [ 4  8  6 ... 10  6  1]\n",
            " [ 4  8  8 ... 10  4  1]]\n",
            "dfd: [[5 1 1 ... 3 1 1]\n",
            " [3 1 1 ... 3 1 1]\n",
            " [4 1 1 ... 3 1 1]\n",
            " ...\n",
            " [3 1 1 ... 2 1 2]\n",
            " [3 1 1 ... 1 1 1]\n",
            " [2 1 1 ... 1 1 1]]\n",
            "dfd: [[ 5  4  4 ...  3  2  1]\n",
            " [ 6  8  8 ...  3  7  1]\n",
            " [ 8 10 10 ...  9  7  1]\n",
            " ...\n",
            " [ 5 10 10 ...  8 10  2]\n",
            " [ 4  8  6 ... 10  6  1]\n",
            " [ 4  8  8 ... 10  4  1]]\n",
            "dfd: [[5 1 1 ... 3 1 1]\n",
            " [3 1 1 ... 3 1 1]\n",
            " [4 1 1 ... 3 1 1]\n",
            " ...\n",
            " [3 1 1 ... 2 1 2]\n",
            " [3 1 1 ... 1 1 1]\n",
            " [2 1 1 ... 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vja-SqbOstqZ"
      },
      "source": [
        "# from sklearn.datasets import make_blobs\n",
        "# X, y = make_blobs(centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40)\n",
        "\n",
        "# accuracy = np.sum(y == y_predict) / len(y)\n",
        "# accuracy\n",
        "s=y_predict.tolist()\n",
        "# s"
      ],
      "execution_count": 479,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhiIZdmXs0UX",
        "outputId": "2bd490b0-f122-435f-9747-462b7c70fa13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "print(confusion_matrix(s,y))\n",
        "print(classification_report(s,y))"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[211  11]\n",
            " [ 30 447]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.95      0.91       222\n",
            "         1.0       0.98      0.94      0.96       477\n",
            "\n",
            "    accuracy                           0.94       699\n",
            "   macro avg       0.93      0.94      0.93       699\n",
            "weighted avg       0.94      0.94      0.94       699\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J2fLylWs5vU",
        "outputId": "ef92edac-3857-4b21-e82e-fd69831ea135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# knn = KNeighborsClassifier(n_neighbors = 15, metric='manhattan')# metric='euclidean') #metric='minkowski') \n",
        "# knn.fit(X_train, y_train) \n",
        "from sklearn import metrics \n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# kmeans.score(X_test, y_test) \n",
        "# y_pred=knn.predict(X_test)\n",
        "acc=(metrics.accuracy_score(s,y)*100)\n",
        "print(acc)    \n",
        "# knn.score(X_test, y_test) \n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "pre=(precision_score(s,y)*100) #average='binary')*100)\n",
        "print(pre)\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "rec=(recall_score(s,y)*100)# average='binary')*100)\n",
        "print(rec)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1=(f1_score(s,y))# average='binary')*100)\n",
        "print(f1) "
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94.13447782546494\n",
            "97.59825327510917\n",
            "93.71069182389937\n",
            "0.9561497326203208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czv6GVYukuyg"
      },
      "source": [
        "## **Final Version of SecureKmeans**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKIYVasGk2Xw"
      },
      "source": [
        "# # Library Declaration  \n",
        "# import numpy as np\n",
        "# import pandas as pd \n",
        "# # Data Input\n",
        "# df = pd.read_table('breast-cancer-wisconsin.data', sep=',', names=[\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\",\"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\",\"Mitoses\",\"Class\"]) \n",
        "# # print(df.head)\n",
        "# # Data Cleaning\n",
        "# df[\"Bare Nuclei\"][df[\"Bare Nuclei\"]=='?']='0'\n",
        "# df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(str).astype(int)\n",
        "# # df.info()\n",
        "# # pd.to_numeric(df[\"Bare Nuclei\"])\n",
        "# # Data Cleaning\n",
        "\n",
        "# df=df.drop([\"Sample code number\"], axis = 1)\n",
        "# # print(df.shape)\n",
        "# # Data Cleaning\n",
        "\n",
        "# def Class_value(Class): \n",
        "#      if Class == 2: \n",
        "#          return 1\n",
        "#      else: \n",
        "#          return 0\n",
        "  \n",
        "# df['Class'] = df['Class'].apply(Class_value) \n",
        "# #df['Class'].head(10)\n",
        "# sf=df\n",
        "# y = sf[\"Class\"].astype(float).values.tolist()\n",
        "# # y\n",
        "\n",
        "# df=df.drop([\"Class\"], axis = 1)\n",
        "\n",
        "# dataset = df.astype(float).values.tolist()\n",
        "\n",
        "# X = df.values #returns a numpy array\n",
        "# X"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GFKEkkEl9Xm"
      },
      "source": [
        "# sse={}\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn.preprocessing import StandardScaler, normalize\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.metrics import silhouette_score\n",
        "\n",
        "# for k in range(1, 10):\n",
        "#     kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X)\n",
        "#     sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\n",
        "# plt.figure()\n",
        "# plt.plot(list(sse.keys()), list(sse.values()))\n",
        "# plt.xlabel(\"Number of cluster\")\n",
        "# plt.ylabel(\"SSE\")\n",
        "# plt.show()"
      ],
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11iw-gjztEPx"
      },
      "source": [
        "# import numpy as np\n",
        "# class Kmeans:\n",
        "  \n",
        "#   def __init__(self, n_clusters=4):\n",
        "#     self.K = n_clusters\n",
        "  \n",
        "#   def fit(self, X):\n",
        "#     self.centroids = X[np.random.choice(len(X), self.K, replace=False)]\n",
        "#     self.intial_centroids = self.centroids\n",
        "#     self.prev_label,  self.labels = None, np.zeros(len(X))\n",
        "#     while not np.all(self.labels == self.prev_label) :\n",
        "#       self.prev_label = self.labels\n",
        "#       self.labels = self.predict(X)\n",
        "#       self.update_centroid(X)\n",
        "#     return self\n",
        "  \n",
        "#   def predict(self, X):\n",
        "#     return np.apply_along_axis(self.compute_label, 1, X)\n",
        "    \n",
        "#   # def distance(self, x1, x2):\n",
        "#   #   disce = 0.0\n",
        "#   #   for i in range(len(x1)-1):\n",
        "#   #     if (x1[i]>=x2[i]):\n",
        "#   #       disce +=(x1[i] - x2[i])\n",
        "#   #     else:\n",
        "#   #       disce += (x2[i] - x1[i])\n",
        "#   #   return disce\n",
        "\n",
        "#   # def compute_label(self, x):\n",
        "#   #   # print(np.sqrt(np.sum((self.centroids - x)**2, axis=1)))\n",
        "#   #   disce = 0.0\n",
        "#   #   for i in range(2):\n",
        "#   #     for j in range(len(x)-1):\n",
        "#   #       if (self.centroids[i][j]>=x[j]):\n",
        "#   #         disce +=(self.centroids[i][j] - x[i])\n",
        "#   #       else:\n",
        "#   #         disce += (x[i] -self.centroids[i][j])\n",
        "#   #   print(disce)\n",
        "#   #   # return np.argmin(disce)\n",
        "\n",
        "#   def compute_label(self, x):\n",
        "#     print(np.sqrt(np.sum((self.centroids - x)**2, axis=1)))\n",
        "#     return np.argmin(np.sqrt(np.sum((self.centroids - x)**2, axis=1)))\n",
        "  \n",
        "#   def update_centroid(self, X):\n",
        "#     self.centroids = np.array([np.mean(X[self.labels == k], axis=0)  for k in range(self.K)])"
      ],
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfhDUjJxFpUo"
      },
      "source": [
        "# kmeans = Kmeans(n_clusters=2).fit(X)"
      ],
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl4XKrZuIct3"
      },
      "source": [
        "# s=kmeans.labels"
      ],
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXzClC0RkTFg"
      },
      "source": [
        "# s"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Mfpm8XlXqW"
      },
      "source": [
        "# from sklearn.metrics import confusion_matrix,classification_report\n",
        "# print(confusion_matrix(s,y))\n",
        "# print(classification_report(s,y))"
      ],
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdMs0VZpjcH3"
      },
      "source": [
        "# # knn = KNeighborsClassifier(n_neighbors = 15, metric='manhattan')# metric='euclidean') #metric='minkowski') \n",
        "# # knn.fit(X_train, y_train) \n",
        "# from sklearn import metrics \n",
        "# from sklearn.metrics import precision_recall_fscore_support\n",
        "# # kmeans.score(X_test, y_test) \n",
        "# # y_pred=knn.predict(X_test)\n",
        "# acc=(metrics.accuracy_score(s,y)*100)\n",
        "# print(acc)    \n",
        "# # knn.score(X_test, y_test) \n",
        "\n",
        "# from sklearn.metrics import precision_score\n",
        "# pre=(precision_score(s,y)*100) #average='binary')*100)\n",
        "# print(pre)\n",
        "\n",
        "# from sklearn.metrics import recall_score\n",
        "# rec=(recall_score(s,y)*100)# average='binary')*100)\n",
        "# print(rec)\n",
        "\n",
        "# from sklearn.metrics import f1_score\n",
        "# f1=(f1_score(s,y))# average='binary')*100)\n",
        "# print(f1) "
      ],
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zveb6Uusjq8N"
      },
      "source": [
        ""
      ],
      "execution_count": 369,
      "outputs": []
    }
  ]
}